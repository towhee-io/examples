{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a293454",
   "metadata": {},
   "source": [
    "# Deep Dive into Question Answering Engine with Towhee\n",
    "\n",
    "In the [previous tutorial](./1_build_question_answering_engine.ipynb), we built and prototyped a proof-of-concept question answering engine. Now, let's feed it with large-scale image datasets, and deploy it as a micro-service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc1a9d",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccbd6b8",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "First we need to install dependencies such as pymilvus, towhee and fastapi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f316af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip -q install pymilvus towhee fastapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d4d29",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "\n",
    "There is a subset of the  [InsuranceQA Corpus](https://github.com/shuzi/insuranceQA)  (1000 pairs of questions and answers) used in this demo, everyone can download on [Github](https://github.com/towhee-io/examples/releases/download/data/question_answer.csv). The dataset is same as our previous tutorial: \"[Build a Question Answer Engine in Minutes](1_build_question_answering_engine.ipynb)\", and to make things easy, we'll repeat the important code blocks below; if you have already downloaded data, please move on to next section.\n",
    "\n",
    "- question_answer.csv: a file containing question and the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72f0bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  595k  100  595k    0     0   215k      0  0:00:02  0:00:02 --:--:--  437k\n"
     ]
    }
   ],
   "source": [
    "! curl -L https://github.com/towhee-io/examples/releases/download/data/question_answer.csv -O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9a51a",
   "metadata": {},
   "source": [
    "To use the dataset to get answers, let's first define the dictionary:\n",
    "\n",
    "- id_answer: a dictionary of id and corresponding answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ff9070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('question_answer.csv')\n",
    "id_answer = df.set_index('id')['answer'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5937ca3",
   "metadata": {},
   "source": [
    "### Create Milvus Collection\n",
    "\n",
    "Before getting started, please make sure you have [installed milvus](https://milvus.io/docs/v2.0.x/install_standalone-docker.md). Next to define the function `create_milvus_collection` to create collection in Milvus that uses the [L2 distance metric](https://milvus.io/docs/v2.0.x/metric.md#Euclidean-distance-L2) and an [IVF_FLAT index](https://milvus.io/docs/v2.0.x/index.md#IVF_FLAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f36afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "connections.connect(host='127.0.0.1', port='19530')\n",
    "\n",
    "def create_milvus_collection(collection_name, dim):\n",
    "    if utility.has_collection(collection_name):\n",
    "        utility.drop_collection(collection_name)\n",
    "    \n",
    "    fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, descrition='ids', is_primary=True, auto_id=False),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=dim)\n",
    "    ]\n",
    "    schema = CollectionSchema(fields=fields, description='reverse image search')\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # create IVF_FLAT index for collection.\n",
    "    index_params = {\n",
    "        'metric_type':'L2',\n",
    "        'index_type':\"IVF_FLAT\",\n",
    "        'params':{\"nlist\":2048}\n",
    "    }\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19712e33",
   "metadata": {},
   "source": [
    "## Making Our Question Answering Engine Production Ready\n",
    "\n",
    "To put the question answering engine into production, we need to feed it with a large-scale dataset and deploy a microservice to accept incoming queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e9e38",
   "metadata": {},
   "source": [
    "### Improve Performance with Parallel Execution\n",
    "\n",
    "We are able to enable parallel execution by simply calling `set_parallel` within the pipeline. It tells towhee to process the data in parallel. Here is an example that enables parallel execution on a pipeline using dpr operator. It can be seen that the execution speed below is nearly two times faster than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b36cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:  101.92725419998169\n"
     ]
    }
   ],
   "source": [
    "import towhee\n",
    "import time\n",
    "\n",
    "collection = create_milvus_collection('qa', 768)\n",
    "\n",
    "t1 = time.time()\n",
    "dc = (\n",
    "    towhee.read_csv('question_answer.csv')\n",
    "      .runas_op['id', 'id'](func=lambda x: int(x))\n",
    "      .text_embedding.dpr['question', 'vec'](model_name=\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "      .runas_op['vec', 'vec'](func=lambda x: x.squeeze(0))\n",
    "      .to_milvus['id', 'vec'](collection=collection, batch=25)\n",
    ")\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Total time: \", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c04d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time with parallel: 58.73357009887695\n"
     ]
    }
   ],
   "source": [
    "collection_parallel = create_milvus_collection('qa_parallel', 768)\n",
    "\n",
    "t1 = time.time()\n",
    "dc = (\n",
    "    towhee.read_csv('question_answer.csv')\n",
    "      .runas_op['id', 'id'](func=lambda x: int(x))\n",
    "      .set_parallel(2)\n",
    "      .text_embedding.dpr['question', 'vec'](model_name=\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "      .runas_op['vec', 'vec'](func=lambda x: x.squeeze(0))\n",
    "      .to_milvus['id', 'vec'](collection=collection_parallel, batch=25)\n",
    ")\n",
    "t2 = time.time()\n",
    "print(\"Total time with parallel:\", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56ff68",
   "metadata": {},
   "source": [
    "### Exception Safe Execution\n",
    "\n",
    "When we have large-scale data, there may be bad data that will cause errors. Typically, we don't want such errors to break the production system. Therefore, the data pipeline should continue to process the rest of the data and report the errors.\n",
    "\n",
    "Towhee supports an exception-safe execution mode that allows the pipeline to continue on exceptions and represent the exceptions with `Empty` values. And user can choose how to deal with the `Empty` values at the end of the pipeline. During the query below, there is a `None` data, and it just prints an error message instead of terminating because it has `exception_safe` and `drop_empty`, as you can see, `drop_empty` deletes `empty` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e5a8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 14:53:14,397 - 4554221056 - dpr.py-dpr:46 - ERROR: Invalid input for the tokenizer: facebook/dpr-ctx_encoder-single-nq-base\n"
     ]
    }
   ],
   "source": [
    "dc = ( towhee.dc(['Is  Disability  Insurance  Required  By  Law?', None])\n",
    "      .exception_safe()\n",
    "      .text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "      .runas_op(func=lambda x: x.squeeze(0))\n",
    "      .milvus_search(collection='question_answer', limit=3)\n",
    "      .runas_op(func=lambda res: [id_answer[x.id] for x in res])\n",
    "      .to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97944078",
   "metadata": {},
   "source": [
    "## Deploy as a Microservice\n",
    "\n",
    "The data pipeline used in our experiments can be converted to a function with `towhee.api` and `as_function()`, as it is presented in the [previous tutorial](./1_build_question_answering_engine.ipynb). We can also convert the data pipeline into a RESTful API with `serve()`, it generates FastAPI services from towhee pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977b255",
   "metadata": {},
   "source": [
    "### Insert Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9119468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import towhee\n",
    "from fastapi import FastAPI\n",
    "from pymilvus import connections, Collection\n",
    "\n",
    "app = FastAPI()\n",
    "connections.connect(host='127.0.0.1', port='19530')\n",
    "milvus_collection = Collection('qa')\n",
    "\n",
    "@towhee.register(name='get_qa_id')\n",
    "def get_qa_id(text):\n",
    "    qa = json.loads(text)\n",
    "    question = qa['Q']\n",
    "    answer = qa['A']\n",
    "    timestamp = int(time.time()*10000)\n",
    "    id_answer[timestamp] = answer\n",
    "    return question, timestamp\n",
    "\n",
    "@towhee.register(name='milvus_insert')\n",
    "class MilvusInsert:\n",
    "    def __init__(self, collection):\n",
    "        self.collection = collection\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        data = []\n",
    "        for iterable in args:\n",
    "            data.append([iterable])\n",
    "        mr = self.collection.insert(data)\n",
    "        self.collection.load()\n",
    "        return str(mr)\n",
    "\n",
    "with towhee.api['text']() as api:\n",
    "    app_insert = (\n",
    "        api.get_qa_id['text', ('question', 'id')]()\n",
    "        .text_embedding.dpr['question', 'vec'](model_name=\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "        .runas_op['vec', 'vec'](func=lambda x: x.squeeze(0))\n",
    "        .tensor_normalize['vec', 'vec']()\n",
    "        .milvus_insert[('id', 'vec'), 'res'](collection=milvus_collection)\n",
    "        .select['id']()\n",
    "        .serve('/insert', app)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752be964",
   "metadata": {},
   "source": [
    "### Search Similar Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f71ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with towhee.api() as api:\n",
    "    app_search = (\n",
    "        api.text_embedding.dpr(model_name=\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "          .runas_op(func=lambda x: x.squeeze(0))\n",
    "          .tensor_normalize()\n",
    "          .milvus_search(collection=milvus_collection, limit=1)\n",
    "          .runas_op(func=lambda res: [id_answer[x.id] for x in res])\n",
    "          .serve('/search', app)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f68ba",
   "metadata": {},
   "source": [
    "### Count Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c56d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with towhee.api() as api:\n",
    "    app_count = (\n",
    "        api.map(lambda _: milvus_collection.num_entities)\n",
    "        .serve('/count', app)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031d284",
   "metadata": {},
   "source": [
    "### Start Server\n",
    "\n",
    "Finally to start FastAPI, there are three services `/insert`, `/search` and `/count`, you can run the following commands to test:\n",
    "\n",
    "> Note that insert data should contain both question and answer, e.g. '{\"Q\": \"The question...?\", \"A\": \"The answer...\"}'\n",
    "\n",
    "```bash\n",
    "# ask a question\n",
    "$ curl -X POST \"http://0.0.0.0:8000/search\"  --data \"Is  Disability  Insurance  Required  By  Law?\"\n",
    "\n",
    "# insert qa data\n",
    "$ curl -X POST \"http://0.0.0.0:8000/insert\"  --data '{\"Q\": \"What is China RMB rate?\", \"A\": \"1.00 CNY->0.149286US Dollar, 6.698573 CNY-> 1.00 US Dollar and 1.00 CNY->0.139041 Euro, 7.192143 CNY -> 1.00 Euro on May 30, 2022.\"}'\n",
    "\n",
    "# count the collection\n",
    "$ curl -X POST \"http://0.0.0.0:8000/count\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79781225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [89586]\n",
      "2022-05-31 14:53:50,423 - 4554221056 - server.py-server:64 - INFO: Started server process [89586]\n",
      "INFO:     Waiting for application startup.\n",
      "2022-05-31 14:53:50,426 - 4554221056 - on.py-on:26 - INFO: Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "2022-05-31 14:53:50,431 - 4554221056 - on.py-on:38 - INFO: Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "2022-05-31 14:53:50,437 - 4554221056 - server.py-server:199 - INFO: Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:58069 - \"POST /search HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58070 - \"POST /insert HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:58071 - \"POST /count HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "2022-05-31 14:54:27,530 - 4554221056 - server.py-server:239 - INFO: Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "2022-05-31 14:54:27,634 - 4554221056 - on.py-on:43 - INFO: Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "2022-05-31 14:54:27,638 - 4554221056 - on.py-on:46 - INFO: Application shutdown complete.\n",
      "INFO:     Finished server process [89586]\n",
      "2022-05-31 14:54:27,641 - 4554221056 - server.py-server:74 - INFO: Finished server process [89586]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app=app, host='0.0.0.0', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8aba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
